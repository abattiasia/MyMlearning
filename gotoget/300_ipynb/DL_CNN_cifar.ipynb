{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-20T12:46:13.897367Z","iopub.execute_input":"2024-09-20T12:46:13.898491Z","iopub.status.idle":"2024-09-20T12:46:14.373868Z","shell.execute_reply.started":"2024-09-20T12:46:13.898442Z","shell.execute_reply":"2024-09-20T12:46:14.372559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.datasets import cifar10\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:46:14.376156Z","iopub.execute_input":"2024-09-20T12:46:14.376717Z","iopub.status.idle":"2024-09-20T12:46:29.891530Z","shell.execute_reply.started":"2024-09-20T12:46:14.376669Z","shell.execute_reply":"2024-09-20T12:46:29.890473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Load the cifar10 Dataset\n(X_train, y_train), (X_test, y_test) = cifar10.load_data()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:46:29.893102Z","iopub.execute_input":"2024-09-20T12:46:29.893989Z","iopub.status.idle":"2024-09-20T12:46:44.627802Z","shell.execute_reply.started":"2024-09-20T12:46:29.893931Z","shell.execute_reply":"2024-09-20T12:46:44.626412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Preprocess the Data\n# Normalize the data by scaling pixel values to be between 0 and 1\nX_train = X_train.astype('float32') / 255\nX_test = X_test.astype('float32') / 255","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:46:44.630987Z","iopub.execute_input":"2024-09-20T12:46:44.631507Z","iopub.status.idle":"2024-09-20T12:46:44.965454Z","shell.execute_reply.started":"2024-09-20T12:46:44.631449Z","shell.execute_reply":"2024-09-20T12:46:44.964082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert labels to one-hot encoding\ny_train = to_categorical(y_train, 10)  # 10 classes (0-9 digits)\ny_test = to_categorical(y_test, 10)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:46:44.967020Z","iopub.execute_input":"2024-09-20T12:46:44.967493Z","iopub.status.idle":"2024-09-20T12:46:44.977663Z","shell.execute_reply.started":"2024-09-20T12:46:44.967439Z","shell.execute_reply":"2024-09-20T12:46:44.976675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the Sequential model\nfrom tensorflow.keras import layers\nmodel_cnn = Sequential()  #models.\n\n# Add layers step-by-step using the add() method\nmodel_cnn.add(layers.InputLayer(input_shape=(32, 32, 3)))  # Input layer for 32x32x3 color images\nmodel_cnn.add(layers.Conv2D(32, (3, 3), activation='relu'))  # First Conv2D layer\nmodel_cnn.add(layers.MaxPooling2D((2, 2)))  # First MaxPooling layer\n\nmodel_cnn.add(layers.Conv2D(64, (3, 3), activation='relu'))  # Second Conv2D layer\nmodel_cnn.add(layers.MaxPooling2D((2, 2)))  # Second MaxPooling layer\n\nmodel_cnn.add(layers.Conv2D(64, (3, 3), activation='relu'))  # Third Conv2D layer\n\nmodel_cnn.add(layers.Flatten())  # Flatten the feature maps\nmodel_cnn.add(layers.Dense(64, activation='relu'))  # Fully connected layer\nmodel_cnn.add(layers.Dense(10, activation='softmax'))  # Output layer for 10 classes\n\n# Compile the model\nmodel_cnn.compile(optimizer='adam',\n              loss='categorical_crossentropy',   #sparse_categorical_crossentropy  ..> only wenn no encoding for y_train\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:46:44.979376Z","iopub.execute_input":"2024-09-20T12:46:44.979860Z","iopub.status.idle":"2024-09-20T12:46:45.226021Z","shell.execute_reply.started":"2024-09-20T12:46:44.979818Z","shell.execute_reply":"2024-09-20T12:46:45.224741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model_cnn.fit(X_train, y_train, epochs=10, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:46:45.227547Z","iopub.execute_input":"2024-09-20T12:46:45.228093Z","iopub.status.idle":"2024-09-20T12:51:59.360999Z","shell.execute_reply.started":"2024-09-20T12:46:45.228038Z","shell.execute_reply":"2024-09-20T12:51:59.359670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\n#model_ann.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)   ->>> ANN\n\n#reshaped_X_train = X_train.reshape(3, 32, 32).transpose(1, 2, 0) \n#X_train = X_train.reshape((X_train.shape[0], 32, 32, 3))\n#y_test = y_test.reshape((y_test.shape[0], 32, 32, 3))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}