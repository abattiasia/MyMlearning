{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import keras\nfrom keras.datasets import fashion_mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.utils import to_categorical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.datasets.fashion_mnist.load_data()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Load the .fashion_mnist Dataset\n\n(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Preprocess the Data\n# Normalize the data by scaling pixel values to be between 0 and 1\nX_train = X_train.astype('float32') / 255\nX_test = X_test.astype('float32') / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Convert labels to one-hot encoding\n# y_train = to_categorical(y_train, 10)  # 10 classes (0-9 digits)\n# y_test = to_categorical(y_test, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the Sequential model\nfrom tensorflow.keras import layers\nmodel_cnn = Sequential()  #models.\n\n# Add layers step-by-step using the add() method\nmodel_cnn.add(layers.InputLayer(input_shape=(28, 28, 1)))  # Input layer for 32x32x3 color images\nmodel_cnn.add(layers.Conv2D(32, (3, 3), activation='relu'))  # First Conv2D layer\nmodel_cnn.add(layers.MaxPooling2D((2, 2)))  # First MaxPooling layer\n\nmodel_cnn.add(layers.Conv2D(64, (3, 3), activation='relu'))  # Second Conv2D layer\nmodel_cnn.add(layers.MaxPooling2D((2, 2)))  # Second MaxPooling layer\n\nmodel_cnn.add(layers.Conv2D(64, (3, 3), activation='relu'))  # Third Conv2D layer\n\nmodel_cnn.add(layers.Flatten())  # Flatten the feature maps\nmodel_cnn.add(layers.Dense(64, activation='relu'))  # Fully connected layer\nmodel_cnn.add(layers.Dense(10, activation='softmax'))  # Output layer for 10 classes\n\n# Compile the model\nmodel_cnn.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',   #sparse_categorical_crossentropy  ..> only wenn no encoding for y_train\n              metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model_cnn.fit(X_train, y_train, epochs=10, validation_split=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n# # Load the dataset\n# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n#  # Normalize the images to [0, 1] range\n# x_train, x_test = x_train / 255.0, x_test / 255.0\n # Build a simple ANN model\n\n# model = Sequential([\n#      Flatten(input_shape=(32, 32, 3)),\n#      Dense(128, activation='relu'),\n#      Dense(10, activation='softmax')\n# ])\n# Compile the model\n###model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n###model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)\n\nmodel_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  #loss='sparse_categorical_crossentropy'\n# Define early stopping callback\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5)\n# Train the model with early stopping\nhistory = model_cnn.fit(X_train, y_train, validation_split=0.2, epochs=30, batch_size=32, callbacks=[early_stopping])\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\ntest_loss, test_acc = model_cnn.evaluate(X_test, y_test)\ntest_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Display the first test image\nplt.imshow(X_test[0]) #, cmap='color')\nplt.title(\"First Test Image\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training and validation accuracy/loss\nplt.figure(figsize=(12, 4))\nclass_names = ['Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n# Display the first 5 test images and predicted labels\npredictions = model_cnn.predict(X_test[:10])\n\nplt.figure(figsize=(10, 2))\nfor i in range(5):\n    plt.subplot(1, 5, i+1)\n    plt.imshow(X_test[i])\n    plt.xticks([])\n    plt.yticks([])\n    #plt.title(f\"Pred: {class_names[predictions[i].argmax()]}\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}